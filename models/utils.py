from collections import OrderedDict
from typing import Dict, List, Optional, Tuple

import cv2
import numpy as np
import torch
from scipy.ndimage.filters import gaussian_filter
from torch import nn
from torch.nn import Module

PEAKS = List[List[Optional[Tuple[int, int, float, int]]]]


def transfer(model: nn.Module, model_weights: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
    """ Transfer caffe model to pytorch which will match the layer name
    :param model: The instance model to load weights to
    :param model_weights: The dictionary containing the caffe weights of the model

    :return: The dictionary containing the transfered pytorch weights
    """
    transfered_model_weights = {}
    for weights_name in model.state_dict().keys():
        transfered_model_weights[weights_name] = model_weights[
            ".".join(weights_name.split(".")[1:])
        ]
    return transfered_model_weights


def set_parameter_requires_grad(model: Module, requires: bool) -> None:
    """ Helper function that sets the requires_grad parameter

    :param model: the model instance to be modified
    :param requires: where to enable or not requires grad
    """
    for param in model.parameters():
        param.requires_grad = requires


def make_layers(block: OrderedDict, no_relu_layers: List[str]) -> nn.Sequential:
    """
    Helper function that transforms a dictionary of layers and parameters into a nn.Sequential object

    :param block: ordered dictionary mapping {layer_name: layer parameters}
    :param no_relu_layers: list of layers that do not require ReLU activation

    :return: a nn.Sequential instance of the transformed block
    """
    layers: List[Tuple[str, nn.Module]] = []
    for layer_name, params in block.items():
        if "pool" in layer_name:
            layer = nn.MaxPool2d(kernel_size=params[0], stride=params[1], padding=params[2])
            layers.append((layer_name, layer))
        else:
            conv2d = nn.Conv2d(
                in_channels=params[0],
                out_channels=params[1],
                kernel_size=params[2],
                stride=params[3],
                padding=params[4],
            )
            layers.append((layer_name, conv2d))
            if layer_name not in no_relu_layers:
                layers.append(("relu_" + layer_name, nn.ReLU(inplace=True)))

    return nn.Sequential(OrderedDict(layers))


def get_peaks_from_image(L: torch.Tensor, padded_shape: torch.Tensor, pad: List[int]) -> PEAKS:
    """ Helper function that extracts keypoints from the confidence maps

    :param L: the confidence map generated by the openpose model
    :param padded_shape: the shape of the padded image
    :param pad: the list of padding values

    :return: a list of list where each sublist contains the peaks
            x-y coordinates, score and id for a given body part
    """
    stride = 8
    thre1 = 0.1
    image_shape = (224, 298)
    peak_counter = 0

    Mconv7_stage6_L2 = L.cpu().numpy()

    # extract outputs, resize, and remove padding
    heatmap = np.transpose(np.squeeze(Mconv7_stage6_L2), (1, 2, 0))  # output 1 is heatmaps
    heatmap = cv2.resize(heatmap, (0, 0), fx=stride, fy=stride, interpolation=cv2.INTER_CUBIC)
    heatmap = heatmap[: padded_shape[0] - pad[2], : padded_shape[1] - pad[3], :]
    heatmap = cv2.resize(heatmap, (image_shape[1], image_shape[0]), interpolation=cv2.INTER_CUBIC)

    all_peaks = []
    for part in range(18):  # ignore background part
        map_ori = heatmap[:, :, part]  # confidence map of a single body part
        one_heatmap = gaussian_filter(
            map_ori, sigma=3
        )  # smooth confidence map by applying a gaussian filter

        map_left = np.zeros(one_heatmap.shape)
        map_left[1:, :] = one_heatmap[:-1, :]
        map_right = np.zeros(one_heatmap.shape)
        map_right[:-1, :] = one_heatmap[1:, :]
        map_up = np.zeros(one_heatmap.shape)
        map_up[:, 1:] = one_heatmap[:, :-1]
        map_down = np.zeros(one_heatmap.shape)
        map_down[:, :-1] = one_heatmap[:, 1:]

        peaks_binary = np.logical_and.reduce(
            (
                one_heatmap >= map_left,
                one_heatmap >= map_right,
                one_heatmap >= map_up,
                one_heatmap >= map_down,
                one_heatmap > thre1,
            )
        )  # transform the map into boolean values
        peaks = list(
            zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0])
        )  # get the position of the peak(s)
        peaks_with_score = [
            x + (map_ori[x[1], x[0]],) for x in peaks
        ]  # get the peak value on the original confidence map
        peak_id = range(peak_counter, peak_counter + len(peaks))
        peaks_with_score_and_id = [
            peaks_with_score[i] + (peak_id[i],) for i in range(len(peak_id))
        ]  # tuple with format (col, row, score, id)

        all_peaks.append(peaks_with_score_and_id)
        peak_counter += len(peaks)

    return all_peaks


def get_body_points(all_peaks: PEAKS) -> Dict:
    """
    Parse image peaks and extract x-y coordinates along with the score

    :return: A dictionary containing x_i, y_i, score_i entries for each peak
    """
    body_dict = {}
    for i, peaks in enumerate(all_peaks):
        # if a given sublist is empty, we can not see that joint
        if len(peaks) == 0:
            body_dict.update({f"x_{i}": np.nan, f"y_{i}": np.nan, f"score_{i}": np.nan})
        else:
            # get the point with the highest score
            peaks = sorted(peaks, key=lambda x: x[2], reverse=True)
            body_dict.update(
                {f"x_{i}": peaks[0][0], f"y_{i}": peaks[0][1], f"score_{i}": peaks[0][2]}
            )
    return body_dict


def padRightDownCorner(img, stride, padValue):
    h = img.shape[0]
    w = img.shape[1]

    pad = 4 * [None]
    pad[0] = 0  # up
    pad[1] = 0  # left
    pad[2] = 0 if (h % stride == 0) else stride - (h % stride)  # down
    pad[3] = 0 if (w % stride == 0) else stride - (w % stride)  # right

    img_padded = img
    pad_up = np.tile(img_padded[0:1, :, :] * 0 + padValue, (pad[0], 1, 1))
    img_padded = np.concatenate((pad_up, img_padded), axis=0)
    pad_left = np.tile(img_padded[:, 0:1, :] * 0 + padValue, (1, pad[1], 1))
    img_padded = np.concatenate((pad_left, img_padded), axis=1)
    pad_down = np.tile(img_padded[-2:-1, :, :] * 0 + padValue, (pad[2], 1, 1))
    img_padded = np.concatenate((img_padded, pad_down), axis=0)
    pad_right = np.tile(img_padded[:, -2:-1, :] * 0 + padValue, (1, pad[3], 1))
    img_padded = np.concatenate((img_padded, pad_right), axis=1)

    return img_padded, pad
